{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import DenseNet121\nimport datetime\n\nclass MyCustomCallback(tf.keras.callbacks.Callback):\n\n  def on_train_batch_begin(self, batch, logs=None):\n    print('Training: batch {} begins in {}'.format(batch, datetime.datetime.now().time()))\n\n  def on_train_batch_end(self, batch, logs=None):\n    print('Training: batch {} ends in {}'.format(batch, datetime.datetime.now().time()))\n\n  def on_test_batch_begin(self, batch, logs=None):\n    print('Validation: batch {} begins in {}'.format(batch, datetime.datetime.now().time()))\n\n  def on_test_batch_end(self, batch, logs=None):\n    print('Validation: batch {} ends in {}'.format(batch, datetime.datetime.now().time()))\n\n\ndirectory = \"../input/editeddatancml/seg_train_small/seg_train/\" #(Alex) Fixed it! now it should work\n\n\nseed_value=123\ntrain = tf.keras.preprocessing.image_dataset_from_directory(\n    directory, labels='inferred', label_mode='categorical', seed=seed_value, color_mode='rgb', batch_size=32, image_size=(150,150), shuffle=True, validation_split=0.25, \n    subset=\"training\")\n\nval = tf.keras.preprocessing.image_dataset_from_directory(\n    directory, labels='inferred', label_mode='categorical', seed=seed_value,\n    color_mode='rgb', batch_size=32, image_size=(150,150), shuffle=True, validation_split=0.25, subset=\"validation\")\n\n##A: Here it throws an error, seems to need more args ( return DenseNet([6, 12, 24, 16], include_top, weights, input_tensor,\n# input_shape, pooling, classes))\nbase_model = DenseNet121(include_top=False, weights=\"imagenet\", input_shape=(150,150,3)) \ninputs = keras.Input(shape=(150, 150, 3))\n\n\n#prediction = Dense(6, activation='soft_max')(x)\nbase_model.trainable= False\n\nx = inputs\nnorm_layer = keras.layers.experimental.preprocessing.Normalization()\nmean = np.array([127.5] * 3)\nvar = mean ** 2\n# Scale inputs to [-1, +1]\nx = norm_layer(x)\nnorm_layer.set_weights([mean, var])\n\n#Maybe add an extra dense layer before\nx = base_model(x, training=False)\n#x = keras.layers.GlobalAveragePooling2D()(x)\nx = keras.layers.Flatten()(x)\nx = keras.layers.Dense(1024, activation='relu')(x)\nx = keras.layers.Dropout(0.35)(x) #should i have dropout layer?\nx = keras.layers.Dense(1024, activation='relu')(x)\noutputs = keras.layers.Dense(6)(x)\n\nmodel = keras.Model(inputs, outputs)\nmodel.summary()\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.CategoricalAccuracy()],\n)\n\nepochs = 20\nmodel.fit(train, epochs=epochs, validation_data=val)\n\n\n_ = model.fit(x_train, y_train,\n          batch_size=32,\n          epochs=1,\n          steps_per_epoch=5,\n          verbose=0,\n          callbacks=[MyCustomCallback()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}